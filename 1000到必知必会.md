### 机器学习算法（包括常用库的使用）
- 回归和分类的区别？
	- 回归：输入变量和输出变量均为连续变量的预测问题
	- 分类：输出变量为有限个离散变量的预测问题
- 为什么会有交叉验证？解决了什么问题？有哪些交叉验证？以及不同的交叉验证有什么优缺点和适用条件？
- 经验误差？结构误差？经验误差最小化？结构误差最小化？
- TP,FN,FP,TN?准确率？精确度？召回率？
- 随机梯度下降，牛顿法（x=x-海塞矩阵的逆矩阵*一阶导数。求二阶偏导，并且求逆矩阵），拟牛顿法（正定矩阵去近似海塞矩阵的逆矩阵，降低计算过程）
- 一元线性回归(对参数求偏导为0，解出参数)，多元线性回归(对参数求偏导，利用梯度下降法，更新参数)
- 最小二乘法(平方损失函数)和梯度下降法（迭代法)的相同点和不同点？
相同点：都是给定数据的情况下，使得损失函数最小化时，求解参数。
不同点：梯度下降可以选择其他的损失函数，但是最小二乘法只能选择平方误差函数；最小二乘可以直接求得全局最小值，但是梯度下降一般只能求得局部最小，且到最小点附近收敛速度会很慢，对初始点的选取极为敏感。
- KNN：K近邻算法(懒惰学习，不进行训练，直接计算得出预测结果)，算法的结果很大程度上取决于k的选择，不能太大，也不能太小。
- 逻辑回归中的损失函数为什么不选平方损失函数？
	- 逻辑回归是监督学习中的一种分类算法，是通过回归的方法来做分类，所以叫逻辑回归。
	- 一开始是通过线性回归和设定阈值的方法来处理分类问题的，但是由于异常值对阈值设定的影响较大，所以改用另一种方法来处理分类问题(logistics)。通过对预测值非线性变换，得到一个预测为正类的概率值g(x)，则预测为负类的概率就是1-g(x)。对于logistics的阈值设定一般根据具体的情况去设定。那么接下来怎么才能让很多数据都分类正确呢？肯定是找一个损失函数来训练样本，进而得到一个可以接受的参数来作为最终的分类参数。一开始用平方损失函数来做分类的损失函数，结果是这个函数是一个非凸函数，所以很难求解到全局最小值，所以只能换损失函数了。选择交叉熵作为逻辑回归的损失函数，再根据梯度下降更新参数。
- 决策树：
	- 信息增益选取特征来构建决策树；
	- 信息增益率；
	- 基尼系数；
	- 处理过拟合的办法：剪枝处理
- k-means:k均值，是一种无监督学习算法，聚类算法中最为简单，高效的
	- 信息思想：指定k个初始质心点，作为聚类的类别，接下来算对每个样本点的距离到质心点的距离，将其类别表为质心所对应的的类别，接下来重新计算质心点的位置，重复上面的两步，知道模型收敛。
- 高斯过程
- 偏差和方差
- 常用距离公式
- 鞍点，如何处理
- 集成学习方法有哪些
- SVM，核函数
- 监督学习，半监督学习，无监督学习，
- 降维方法有哪些，
- 聚类算法有哪些
- RF，GBDT,XGBoost,lightGBM
- CART,C4.5,ID3的区别
- 特征工程
- CART 
- 贝叶斯网络
- 混合高斯模型
- 隐马尔可夫模型
- 


### 深度学习算法（主要是pytorch和keras等其他的库）
- Inception v1-v4; ResNet,ResNext,DenseNet,SENet的总结
- 目标检测系列RCNN，Fast RCNN，Faster RCNN,YOLO,SSD,YOLO v2,YOLO v3,SSD v2,FCN
- BN层，BN层有什么作用
- 介绍下CNN
- MaxPooling，AvgPooling
- 画下inception v3 和ResNet最核心的结构
- 主流CNN在ImageNet上的准确率
- attention机制
- loss
- Normalization
- NLP:RNN,LSTM
- 优化方法
- 上采样，反卷积
- 有哪些激活函数，各自的优点
- 过拟合是什么，如何处理
- 你认为深度学习是最好的算法吗？有哪些场景不适合深度学习？
- 数据不均衡问题
- BP算法推导
- 全连接层的作用
- softmax，softmaxloss，cross entropy
- 为什么训练不收敛，如何解决
- 不收敛和过拟合的区别
- SGD参数设置，权值衰减是什么意思
- LSTM和naive RNN的区别
- 人脸识别
- OCR技术
- 深度学习在图像领域效果为什么这么好
- DL和ML的区别
- conv,pool反向传播怎么做？
- 卷积层参数量，计算量是多少？
- 感受野的计算
- 轻量型网络
- LSTM用在行为识别为什么不好
- 为什么梯度反方向是函数值下降最快的方向？
- bagging，boosting
- dropout
- 各种损失函数，交叉熵多标签分类问题
- 线性回归和逻辑回归的区别
- 权值初始化方法有哪些
- 性能度量方法
- VGG16与ResNet152那个参数量大
- 最小二乘法
- 图像库相似搜索
- CNN为什么用relu,为什么不用sigmoid
- 目标检测，小目标问题
- 某个类别准确率不搞怎办，混淆矩阵互分严重怎么办
- untrimmed视频如何处理
- 精确率很高，召回率很低是什么原因，如何解决



### 图像处理
- 图像特征提取的算法有哪些，各自优缺点，适用范围
- 图像边缘检测算法
- 霍夫变换
- 图像平移
- 图像开闭操作
- 图像旋转
- 最近邻差值，双向性差值
- 图像重建质量评价标准
- 光流法
- 图像去噪方法
- 度量图像patch相似度方法
- 传统图像处理CDC？
- 傅里叶变换
- 图像融合算法有哪些
- 图像增强算法有哪些
- 图像滤波方法
- 直方图均衡
- 手动实现卷积
- LBP
- HOG
- HAAR
- harri角点
- sift
- surf
- DCT，DFT，IDFT
- 图像目标检测与跟踪
- 图像中求最值
- 理解图像中的低频分量和高频分量
### 推荐系统

### 视觉计算，数字图像处理，计算及图形学

### 基础算法

### 深度学习框架

### 语言和库
- 函数传参会改变参数本身吗
- xrange,range的区别
- 为什么python的多线程鸡肋
#### Pandas
- map({old:newdata,old:newdata})  就是将old替换为new的
- axis=1表示执行列之间的操作，最后得到的也是一列

### 数学
- 概率分布
- 期望，方差，协方差，相关系数
- 假设检验
- 最大似然估计，贝叶斯估计

### 计算机基础
- 进程线程的区别
- TCP传输的可靠性是如何保证的
- 
### 面试
- 自我介绍
- 你和竞争者相比的优势是什么
- 实习收获了什么
- 从面试官身上学到了什么
- 秋招意向的企业有哪些
- 你为什么想来我们公司?
- 你来了之后的三年怎么打算的?
- 讲一讲实习公司的产品架构,比如一个新的需求产生到落地的流程是怎样?
- 优缺点
- 介绍项目，难点，从中学到什么，重新做如何改进
- 期望薪资
- 自己主动学习过哪些知识，通过什么方式学的
- 后面打算学习什么知识，为什么
- 英语怎么样
- 兴趣
- 团队合作遇到的分歧
- 有没有投过其他公司,有拿到offer吗?
- 项目中怎么分工的，有遇到过水平低的吗，是怎么沟通的
- 对你帮助很大的一个人
- 学习的路径，怎么学习
- 被批评以后的心里状态
- 实习经历
- 实习时间
- 人生理想
- 最成功的一件事
- 小时候印象最深的一件事
### 简历
- 简历项目该怎么写？项目介绍，用到的核心技术，自己解决的内容，遇到什么难点，怎么解决的，最后的效果
- 职业规划：


### 面试，笔试技巧
- 自我介绍
- 对这个岗位，你有什么优势？
- 对面试的公司有什么了解
- 找工作的情况，有什么offer
- 找工作的标准
- 对实习公司的评价
- 为什么不留在实习公司
- 最好，最成功的的一件事
- 失败的事情或者没有达到的期望
- 人生理想
- 期望工资，工作地点，工作时间
- 在那些领域有较深的理解
- 有什么兴趣爱好



#### 面试

- 对算法的理解，数据处理问题，数据不平衡问题，过拟合，欠拟合，交叉验证，模型评估，模型选择，特征工程的问题。模型之间的本质区别，使用什么样的训练场景。
- 项目方面，问的细节更多，为什么这么做？如何调整模型，在项目中具体负责的模块中的技术细节，遇到的问题，使用的什么损失函数，如何优化？怎么训练模型的，用的什么数据集，优化算法的选择做过哪些，为啥这样做？
- 讲述项目的背景，规模，用时，用到的技术以及庚哥模块。重点突出自己比较熟悉的技术。主动说出自己做的那些事，模型中的细节。尽可能把自己熟悉的说出来
- 一定要主动：作为面试者，应该能够主动并且逻辑清楚的说出自己的项目的哪些亮点。



- 标量，向量，矩阵，张量
- 范数：衡量向量的大小；L1范数，L2范数，Lp范数，最大值范数，最小值范数
  ![3.png](https://i.loli.net/2020/02/22/OEcNzdXHyBkm4U6.png)

- 对角矩阵：除了对角线上的元素，其他都为0的矩阵。对称矩阵的转置还是本身。
- 正交矩阵：指行向量和列向量是分别标准正交的方阵。A
  ⊤A = AA⊤ = I

- 特征分解：将矩阵分解成一组特征向量和特征值